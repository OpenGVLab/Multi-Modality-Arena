 # Copyright (c) 2022, salesforce.com, inc.
 # All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # For full license text, see the LICENSE file in the repo root or https://opensource.org/licenses/BSD-3-Clause

datasets:
  coco_vqa:
    data_type: images
    build_info:
      storage: bliva/data/coco
      vis_root: bliva/data/coco/images

    # data_dir: ${env.data_dir}/datasets
    # data_type: images # [images|videos|features]

    # build_info:
    #   # Be careful not to append minus sign (-) before split to avoid itemizing
    #   annotations:
    #     train:
    #       url:
    #           - https://storage.googleapis.com/sfr-vision-language-research/LAVIS/datasets/vqav2/vqa_train.json
    #           - https://storage.googleapis.com/sfr-vision-language-research/LAVIS/datasets/vqav2/vqa_val.json
    #       storage:
    #           - data/coco/annotations/vqa_train.json
    #           - data/coco/annotations/vqa_val.json
    #     val:
    #       url:
    #           # TODO make this order insensitive
    #           - https://storage.googleapis.com/sfr-vision-language-research/LAVIS/datasets/vqav2/vqa_val_eval.json
    #           - https://storage.googleapis.com/sfr-vision-language-research/LAVIS/datasets/vqav2/answer_list.json
    #           - https://storage.googleapis.com/sfr-vision-language-research/LAVIS/datasets/vqav2/v2_OpenEnded_mscoco_val2014_questions.json
    #           - https://storage.googleapis.com/sfr-vision-language-research/LAVIS/datasets/vqav2/v2_mscoco_val2014_annotations.json
    #       storage:
    #           - data/coco/annotations/vqa_val_eval.json
    #           - data/coco/annotations/answer_list.json
    #           - data/coco/annotations/v2_OpenEnded_mscoco_val2014_questions.json
    #           - data/coco/annotations/v2_mscoco_val2014_annotations.json
    #     test:
    #       url:
    #           - https://storage.googleapis.com/sfr-vision-language-research/LAVIS/datasets/vqav2/vqa_test.json
    #           - https://storage.googleapis.com/sfr-vision-language-research/LAVIS/datasets/vqav2/answer_list.json
    #       storage:
    #           - data/coco/annotations/vqa_test.json
    #           - data/coco/annotations/answer_list.json
    #   images:
    #       storage: data/coco/images/
